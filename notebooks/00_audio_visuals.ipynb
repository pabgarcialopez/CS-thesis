{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Waveform and Mel-Spectrogram Visualization\n",
    "This notebook demonstrates how to visualize an audio waveform and its corresponding Mel-spectrogram using the NSynth dataset and torchaudio library. The steps involved are as follows:\n",
    "\n",
    "1. **Instantiate the Raw Dataset**: Load the 'training/validation/testing' split of the NSynth dataset without any transformation.\n",
    "\n",
    "2. **Instantiate the MelSpectrogram Transformation**: Define the parameters for converting the audio waveform into a Mel-spectrogram.\n",
    "\n",
    "3. **Select an Example**: Choose an example from the dataset to visualize.\n",
    "\n",
    "4. **Plot the Waveform**: Visualize the raw audio waveform.\n",
    "\n",
    "5. **Apply the MelSpectrogram Transformation**: Convert the waveform into a Mel-spectrogram.\n",
    "\n",
    "6. **Convert to Decibels**: Optionally, convert the Mel-spectrogram to decibels for better visualization.\n",
    "\n",
    "7. **Plot the Mel-Spectrogram**: Visualize the Mel-spectrogram in decibels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook Python executable: /Users/pablogarcialopez/.pyenv/versions/TFG-info/bin/python\n",
      "/Users/pablogarcialopez/.pyenv/versions/TFG-info/bin/python\n",
      "Name: deeplake\n",
      "Version: 3.9.44\n",
      "Summary: Activeloop Deep Lake\n",
      "Home-page: \n",
      "Author: activeloop.ai\n",
      "Author-email: support@activeloop.ai\n",
      "License: MPL-2.0\n",
      "Location: /Users/pablogarcialopez/.pyenv/versions/3.12.7/envs/TFG-info/lib/python3.12/site-packages\n",
      "Requires: aioboto3, boto3, click, humbug, lz4, nest_asyncio, numpy, pathos, pydantic, pyjwt, tqdm\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Notebook Python executable:\", sys.executable)\n",
    "!which python\n",
    "!pip show deeplake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook Python executable: /Users/pablogarcialopez/.pyenv/versions/TFG-info/bin/python\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pablogarcialopez/.pyenv/versions/TFG-info/lib/python3.12/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (4.1.13) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n",
      "UsageError: Line magic function `%which` not found.\n"
     ]
    }
   ],
   "source": [
    "%run init_notebook.py\n",
    "\n",
    "import torchaudio\n",
    "from src.dataset import NSynth\n",
    "from torchaudio.transforms import MelSpectrogram\n",
    "from src.utils.audio_plotting import *\n",
    "from src.deeplake_dataset import DeepLakeNSynth\n",
    "\n",
    "\n",
    "\n",
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "# Visualization of an audio waveform without transformation, and its Mel-spectrogram\n",
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "# 1) Instantiate the raw dataset\n",
    "# raw_dataset = NSynth('testing')\n",
    "raw_dataset = DeepLakeNSynth('test')\n",
    "\n",
    "# 2) Instantiate the MelSpectrogram transformation\n",
    "mel_transform = MelSpectrogram(\n",
    "    sample_rate=16000,\n",
    "    n_fft=1024,\n",
    "    hop_length=501,\n",
    "    n_mels=64,\n",
    "    normalized=True\n",
    ")\n",
    "\n",
    "# 3) Select an index to view an example\n",
    "metadata, waveform, sample_rate = raw_dataset[0]  # example of index 0\n",
    "# waveform.shape -> [1, num_samples], since it is mono\n",
    "\n",
    "# 4) Plot waveform\n",
    "plot_waveform(waveform)\n",
    "\n",
    "# 5) Apply the transformation to obtain the spectrogram\n",
    "mel_spec = mel_transform(waveform)  # Returns [1, n_mels, time_frames]\n",
    "# print(\"Shape: \", mel_spec.shape)    # Returns [1, 64, 126]\n",
    "\n",
    "# 6) Convert to decibels for better visualization\n",
    "db_transform = torchaudio.transforms.AmplitudeToDB(stype=\"power\")\n",
    "mel_spec_db = db_transform(mel_spec)\n",
    "\n",
    "# 7) Plot the Mel-spectrogram\n",
    "plot_spectogram(mel_spec_db)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFG-info",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
